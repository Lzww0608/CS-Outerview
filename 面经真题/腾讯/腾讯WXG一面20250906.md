# 腾讯WXG一面20250906

1.自我介绍
2.实习转正情况

Raft开始
3.介绍raft
4.何时发起leader选举
5.如何避免选举失败（超时时长随机化）
6.raft集群有没有不可用的时间，比如日志提交时？无，高可用，日志写入期间向leader读老日志
7.为什么要大于N/2的节点确认后才提交日志，小于N/2行吗？不向从节点确认行吗？
8.raft如何保障leader的日志是最新的raft这块结束，猫猫个人觉得答得还行，没有被某个问题卡住

网络开始
9.读过nginx源码没咋可能读过（

## 10.TCP长连接和短连接，什么时候用

低频次、无状态、非交互式的场景用短连接，其它的一般长连接

1. 交互频率低、周期性长
2. 并发量巨大，但是单次请求快
3. 服务端无状态

场景：

	1. 嵌入式 或 IoT设备
 	2. DNS查询



11.心跳有什么用 检测异常连接，防止中间设备如NAT、防火墙等清除会话（这里一开始记错了，说成了是TCP长时间没消息会断开连接，引得面试官质疑，当场百度，我忏悔鸣鸣，TCP有keep alive，默认不开启，不会自动断开连接，但是中间设备会自动清除会话）



OS开始

## 12.C++和Go的区别，从服务端编程的角度讲讲



| 特性         | C++                                                      | Go                                                     |
| ------------ | -------------------------------------------------------- | ------------------------------------------------------ |
| **核心哲学** | 极致控制，零成本抽象                                     | 工程效率，并发至简                                     |
| **并发模型** | 线程/异步/协程 (复杂)                                    | Goroutine + Channel (简单)                             |
| **内存管理** | 手动 / RAII                                              | 自动GC                                                 |
| **性能**     | 峰值性能极高                                             | 并发吞吐量极高                                         |
| **开发效率** | 较低，学习曲线陡峭                                       | 极高，学习曲线平缓                                     |
| **工具链**   | 复杂，分散                                               | 统一，开箱即用                                         |
| **部署**     | 较复杂 (依赖管理)                                        | 极简单 (静态二进制)                                    |
| **适合场景** | **游戏后端、数据库、搜索引擎、高频交易、计算密集型服务** | **微服务、API网关、云原生应用、中间件、I/O密集型服务** |



13.C++和Go的协程实现对比

## 14.协程什么时机切换

#### 1. 隐式的协作式切换（最常见）

#### **几乎所有的标准库中可能引起阻塞的调用，都会触发调度器进行切换**。这包括：

- 所有网络库 (net) 的操作。
- 所有Channel (chan) 操作。
- 所有同步原语 (sync) 的阻塞操作。
- time包中的睡眠和定时器。

#### 2. 显式的协作式切换

开发者可以手动建议调度器进行切换。

- runtime.Gosched(): 调用此函数会使当前Goroutine主动放弃P，让出CPU时间片，并被放回全局运行队列。调度器会立即调度其他Goroutine。

#### 3. 抢占式调度（Go的“杀手锏”）

为了防止某个CPU密集型的Goroutine（例如一个没有任何阻塞操作的超长循环）饿死其他Goroutine，Go实现了抢占机制。



15.协程比线程的优势

## 16.协程切换，需要保存哪些上下文？
答得PC、SP，寄存器中一些其它值

1. **指令指针 (Instruction Pointer / Program Counter)**：这是最重要的部分。它记录了协程被挂起时执行到了哪一条CPU指令。当协程被恢复时，CPU需要知道从哪里继续执行。
2. **栈指针 (Stack Pointer)**：每个协程都有自己的调用栈，用于存放函数的局部变量、参数、返回地址等。栈指针指向当前栈的栈顶。保存它，是为了在协程恢复时，能正确地找到并使用它自己的栈。
3. **部分CPU寄存器 (CPU Registers)**：当协程被挂起时，一些计算的中间结果可能还存放在CPU的通用寄存器中。为了在恢复后能继续这些计算，这些寄存器的值也需要被保存。

无栈协程实现时会将**挂起点 + 局部变量**放到堆上的**协程帧**中



17.寄存器中保存了哪些信息？
我说局部变量、参数、临时值啥的，这里面试官质疑了一下，我又说和CPU架构有关，x86和RISC-V这些不同

18.上下文保存在哪里
我回答栈，或者特殊的页面上，和架构有关

19.函数调用时如何切换上下文的
函数调用信息保存在栈帧中，通过栈帧指针实现函数跳转

20.具体一点，说说函数调用的过程，哪些信息保存在哪里，哪些是调用者保存的哪些是被调用者保存的
真记不清了，猫猫举了一个进程的例子，进程的栈中切分为多个函数的栈帧，按函数的调用顺序从下至上布局，通过栈帧指针的移动实现函数调用，同时函数的局部变量、返回值之类的保存在栈帧中，总之我答得很模糊，面试官不太满意。
21.虚拟内存
22.TLB为什么快
TLB可以缓存，页表查找是需要多级映射
23.吧啦吧啦，问了一堆问题，大概就是问虚拟内存要怎么分配，物理内存又要怎么分配答了写时复制的一点东西，先分配虚拟内存，实际要用时触发page fault，分配物理内存
24.哪些内存分配在栈上，哪些内存分配在堆上，咋分配的，通过啥函数分配局部变量啥的在栈上，动态分配的在堆上，小内存用brk，移动堆顶指针，连续的，大内存用mmap，创建独立的内存映射。（其实还有个内存池，忘了）pooo

25.mmap分配的内存在哪
栈和堆中间的内存映射区
26.内存布局，内核态和用户态在哪
27.为什么进程切换比线程慢
页表切换、CPU缓存命中率降低（这一点被面试官质疑了，没搞懂他的说法）
28.切换页表的过程为什么会很慢？难道不是就一个页表指针切换的事吗？蒙了，我解释了一下两个进程位于不同的地址空间，实际上没有“指针”这种说法，但还是解释不出为什么页表切换为什么慢。经过面试官提醒，是TLB刷新的原因，页表切换其实是很快的，关键在于TLB会完全刷新。
OS到此结束